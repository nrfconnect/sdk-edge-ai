.. _edge_impulse_integration:

Edge Impulse integration
########################

.. contents::
   :local:
   :depth: 2

`Edge Impulse`_ is a development platform that can be used to enable `embedded machine learning`_ on |NCS| devices.
You can use this platform to collect data from sensors, train a machine learning model, and then deploy it to your Nordic Semiconductor's device.

Integration prerequisites
*************************

Before you start the |EAI| integration with Edge Impulse, make sure that the following prerequisites are completed:

* :ref:`setup_sdk`
* Setup of the required Development Kit (DK).
* Creation of an `Edge Impulse studio account <Edge Impulse studio signup_>`_ and an Edge Impulse project.

Solution architecture
*********************

The Edge Impulse integration consists of three main components:

* Edge Impulse SDK - A C++ library that provides the inference engine and digital signal processing (DSP) functions required to run machine learning models on embedded devices.
  The SDK is integrated into the build system as a Zephyr module through the west manifest file of the |EAI|.
* Deployed ML model - A Zephyr library package generated by Edge Impulse Studio that contains your trained model's parameters.
  This is provided as a :file:`zip` archive with C and C++ source files that are compiled together with your application.
* Application code - Your |NCS| application that collects sensor data, feeds it to the inference engine through the Edge Impulse SDK API, and processes the classification results.

The typical workflow involves collecting sensor samples, running inference using a sliding window approach, and interpreting the classification results to make decisions or trigger actions (see :ref:`hello_ei_sample` sample).

Integration overview
********************

Before integrating the Edge Impulse machine learning model into an |EAI| application, you must prepare and deploy the machine learning model for your embedded device.
This model is prepared using the `Edge Impulse studio`_ external web tool.
It relies on sensor data that can be provided by different sources, for example data forwarder.

.. note::
   You can collect data using either a development board that is supported directly by Edge Impulse or your mobile phone.
   Alternatively, you can modify the :ref:`ei_data_forwarder_sample` sample to forward data from a sensor that is connected to any board available in the |NCS|.

You must include the deployed machine learning model sources in your |EAI| application.

Integration steps
*****************

Complete the following steps to generate the archive and add it to the build system:

1. :ref:`ug_edge_impulse_adding_preparing`
#. :ref:`ug_edge_impulse_adding_building`

.. _ug_edge_impulse_adding_preparing:

.. rst-class:: numbered-step

Preparing the machine learning model
====================================

1. Prepare your own machine learning model.

   To prepare a machine learning model, use `Edge Impulse studio`_ and follow one of the tutorials described in `Edge Impulse getting started guide`_.
   For example, to test the solution, you can try the `Continuous motion recognition tutorial`_.
   You will complete the following steps:

   a. Collect data from sensors and upload them to the Edge Impulse studio.
   #. Design your machine learning model (an *impulse*).

#. Deploy your machine learning model to use it on an embedded device by following one of the two methods:
   You can obtain a library in two ways:

   .. tabs::

      .. group-tab:: Using |EIS| web interface

         a. Go to the :guilabel:`Deployment` tab and select :guilabel:`Zephyr library`.
            This will generate a :file:`zip` file that contains source files defining the |EI| ML model.

         .. figure:: ./images/ei_deploy.png
            :scale: 50 %
            :alt: Model deployment in |EIS| dashboard

            Model deployment in |EIS| dashboard

         .. note::
            Edge Impulse supports multiple deployment formats, some of which are compatible with |NCS| applications.
            However, this instruction focuses on the Zephyr library deployment format.

      .. group-tab:: Using |EI| west extensions

         |EI| provides west command extensions that let you build and deploy the machine learning model from |EIS| using the command line instead of the web interface.
         The commands are already configured in the |EAI| west manifest and are ready to use.

         a. Find two parameters that are required by the commands:

            * ``Project ID`` - You can find it in the :guilabel:`Project info` panel under :guilabel:`Dashboard`.

               .. figure:: ./images/ei_project_id.png
                  :scale: 50 %
                  :alt: Project ID in |EIS| dashboard

                  Project ID in |EIS| dashboard

            * ``API key`` - You can find it under the :guilabel:`Keys` tab in the |EI| project dashboard.

               .. figure:: ./images/ei_api_key.png
                  :scale: 50 %
                  :alt: API key under the Keys tab in |EIS|

                  API key under the Keys tab in |EIS|

         #. Build the machine learning model by running the following command:

            .. code-block:: console

               west ei-build -p <PROJECT_ID> -k <API_KEY>

         #. Deploy the machine learning model by running the following command:

            .. code-block:: console

               west ei-deploy -p <PROJECT_ID> -k <API_KEY>

            As a result, file :file:`ei_model.zip` is downloaded to your working directory.

         For more details on how to use these commands, see `Automated Deployment with West Commands`_ documentation.

.. _ug_edge_impulse_adding_building:

.. rst-class:: numbered-step

Building an application with machine learning model
===================================================

You have to complete the following configuration steps to be able to build your application including the deployed |EI| machine learning model:

1. Make sure that the following Kconfig options are enabled:

   * ``CONFIG_CPP``
   * ``CONFIG_STD_CPP11``
   * ``CONFIG_REQUIRES_FULL_LIBCPP``
   * ``CONFIG_EDGE_IMPULSE_SDK``

   .. note::
      The ``CONFIG_FPU`` Kconfig option is implied by default if floating point unit (FPU) is supported by the hardware.
      Using FPU speeds up calculations.

#. Make sure that the ``CONFIG_FP16`` Kconfig option is disabled.
   The |EI| library is not compatible with half-precision floating point support introduced in Zephyr.

#. If you want to call |EI| API directly from C code, you must define the following macros in your application's :file:`CMakeLists.txt` file:

   .. code-block:: cmake

      zephyr_compile_definitions(
         EI_C_LINKAGE=1
         EIDSP_SIGNAL_C_FN_POINTER=1
      )

   Check `Using the library from C`_ for more information.

#. Unpack the :file:`zip` archive with the deployed machine learning model and add the following to your application's :file:`CMakeLists.txt` file:

   .. code-block:: cmake

      add_subdirectory(ei_model)

   Alternatively, you can automate the unpacking as part of the build process using CMake's ``FetchContent`` module.
   This approach automatically extracts the archive during configuration:

   .. code-block:: cmake

      include(FetchContent)

      FetchContent_Declare(
         ei_model
         URL ${CMAKE_CURRENT_SOURCE_DIR}/ei_model.zip
      )

      FetchContent_MakeAvailable(ei_model)

.. _ug_edge_impulse_building:

Applications and samples
************************

The following samples demonstrate the Edge Impulse integration in the |EAI|:

* :ref:`ei_data_forwarder_sample` sample - Demonstrates how you can send sensor data to |EIS| using `Edge Impulse's data forwarder`_.
* :ref:`hello_ei_sample` sample - Demonstrates the deployment of models in |EI| and usage of the inference engine provided by |EI| SDK.
