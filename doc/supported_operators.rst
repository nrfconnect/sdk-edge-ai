.. _supported_operators:

Supported operators
###################

.. contents::
   :local:
   :depth: 2

This section describes the model structure constraints and the set of operators supported by the Axon Compiler.

Model structure
***************

The Axon Compiler has the following constraints on model structure:

* Supports 8-bit quantized input and output for all layers, with an option to use int32 model output with a configurable radix.
* Supports stateful behavior between inferences when declared using VarHandle, ReadVariable, or AssignVariable.
* Allows a maximum of two inputs per node.
* Supports maximum tensor sizes (height, width, channels) of 1024, 1024, and 512.
* Provides native activation functions: ReLU, ReLU6, and LeakyReLU.
* Provides CPU activation functions: Sigmoid, Tanh, and Softmax.

Operators
*********

The following operators are supported in the current version of Axon Compiler:

Convolution operators
=====================

.. list-table::
   :header-rows: 1

   * - Operator
     - Notes / limitations
     - Target
     - Compiler version
   * - Conv1D
     - | Max filter width: 32
       | Max filter height: 16
       | Max stride: 31
     - Axon NPU | CPU
     - 1.0.0
   * - Depthwise Conv1D
     - | Max filter width: 32
       | Max filter height: 16
       | Max stride: 31
     - Axon NPU | CPU
     - 1.0.0
   * - Conv2D
     - | Max filter dimensions: 16 x 16
       | Max stride: 31
     - Axon NPU | CPU
     - 1.0.0
   * - Depthwise Conv2D
     - | No channel multipliers supported
       | Max filter dimensions: 16 x 16
       | Max stride: 31
     - Axon NPU | CPU
     - 1.0.0

Fully connected layer
=====================

.. list-table::
   :header-rows: 1

   * - Operator
     - Notes / limitations
     - Target
     - Compiler version
   * - Fully Connected
     - | Maximum input vector length: 2048
       | Maximum number of neurons: 2048
     - Axon NPU | CPU
     - 1.0.0

Pooling operators
=================

.. list-table::
   :header-rows: 1

   * - Operator
     - Notes / limitations
     - Target
     - Compiler version
   * - Average Pooling
     - | No padding
       | Max filter dimensions: 32 x 32
       | Minimum kernel size: 2
       | Maximum input/output size: 1024
     - Axon NPU | CPU
     - 1.0.0
   * - Max Pooling
     - | Max filter dimensions: 32 x 32
       | Maximum input/output size: 1024
     - Axon NPU | CPU
     - 1.0.0
   * - Mean
     - Includes global average pooling functionality
     - Axon NPU | CPU
     - 1.0.0
   * - Global Average Pooling
     - Implemented internally as Mean
     - Axon NPU | CPU
     - 1.0.0

Elementwise Operators
=====================

.. list-table::
   :header-rows: 1

   * - Operator
     - Notes / limitations
     - Target
     - Compiler version
   * - Add
     - Vector operation with broadcast on height and/or width
     - Axon NPU | CPU
     - 1.0.0
   * - Multiply
     - Vector operation with broadcast on height and/or width
     - Axon NPU | CPU
     - 1.0.0

Tensor manipulation operators
=============================

.. list-table::
   :header-rows: 1

   * - Operator
     - Notes / limitations
     - Target
     - Compiler version
   * - Strided Slice
     - Max stride: 31
     - Axon NPU | CPU
     - 1.0.0
   * - Concatenate
     - No additional limitations specified
     - Axon NPU | CPU
     - 1.0.0
   * - splitV
     - No additional limitations specified
     - Axon NPU | CPU
     - 1.0.0

Limitations and unsupported operators
*************************************

The following operators are not supported in the current version of Axon Compiler:

* Recurrent layers:

  * GRU
  * LSTM

* Attention layers

Additionally, the current limitations include:

* Reshape Operator Constraints - Although Reshape is supported, it introduces complexity in certain graph topologies and may cause axis or dimension mismatches in specific sequences.
  The following patterns can cause issues:

  * Conv → GlobalAveragePool (keep_dim: true) → Flatten → Dense  
    May produce axis/dimension errors.
  * Conv → GlobalAveragePool (keep_dim: false) → Dense  
    May exhibit similar issues.
  * FC → Reshape → Conv  
    May fail depending on axis handling.

  Working patterns include:

  * Conv → Reshape → FC
  * Certain FC → Reshape → Conv cases when generated by the platform constructor.

  Careful axis alignment and tensor shape validation are required when using Reshape between heterogeneous layers.

* Dilation support constraints:

  * Depthwise convolution with dilation is not properly handled by the compiler.
  * Only trivial cases where output dimensions are 1 x 1 may be supported.
  * General dilation with output dimensions larger than 1 x 1 is not supported.

  Workarounds for larger outputs would require repeated Strided Slice operations to manually construct intermediate tensors, which significantly increases model complexity and is not recommended.

* Excessive use of CPU‑executed activations:
  * Sigmoid
  * Tanh

Model design recommendations
****************************

This section provides practical guidance for designing models that compile successfully and run efficiently on the Axon platform.

Preferred architectures
=======================

When designing models for Axon, favor convolution‑based architectures with the following characteristics:

* Using CNN building blocks, such as:
  * Conv1D or Conv2D layers
  * Depthwise separable convolutions without channel multipliers
  * MaxPooling or AveragePooling layers
  * Mean for implementing global average pooling
  * Fully connected layers that stay within supported size limits

* Using activation functions optimized for NPU execution:
  * ReLU
  * ReLU6
  * LeakyReLU

Architectural constraints
=========================

To stay within compiler and hardware limits, ensure that the model structure adheres to the following constraints:

* Limiting tensor dimensions:
  * Spatial dimensions (height and width) to 1024 or less
  * Channel count to 512 or less

* Limiting fully connected layers:
  * Input vector size to 2048 or less
  * Number of neurons to 2048 or less

* Limiting graph complexity:
  * Using no more than two inputs per node
  * Avoiding complex reshape patterns between convolutional and dense layers

* Avoiding unsupported convolution patterns:
  * Dilation, unless the output dimension is 1 x 1
  * Depthwise convolution with dilation

Quantization guidance
=====================

To achieve optimal performance and predictable accuracy:

* Train models using 8‑bit quantization awareness when targeting deployment on Axon.
* If Sigmoid or Tanh activations are required, consider training with piecewise linear approximations to minimize accuracy degradation.

Deployment strategy
===================

For time‑series and embedded use cases, the following architectural patterns are recommended:

* Typical Conv1D‑based pipelines:
  * Conv1D → ReLU → Pooling → Conv1D → ReLU → Global Average (Mean) → Dense

* Depthwise‑separable pipelines:
  * Depthwise Conv → Pointwise Conv → ReLU → Pooling → Dense

* Fully convolutional models:
  * Convolutional layers followed by final Mean aggregation

When replacing recurrent or attention‑based models, consider convolutional alternatives such as:

* Temporal convolutional networks without dilation
* Stacked Conv1D blocks combined with pooling and global averaging

These patterns maximize compatibility, performance, and compilation success on the Axon platform.
